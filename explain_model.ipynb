{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Literal, Optional, Tuple, Union\n",
    "\n",
    "import einops as E\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from universeg.nn import CrossConv2d\n",
    "from universeg.nn import reset_conv2d_parameters\n",
    "from universeg.nn import Vmap, vmap\n",
    "from universeg.validation import (Kwargs, as_2tuple, size2t, validate_arguments,\n",
    "                         validate_arguments_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nonlinearity(nonlinearity: Optional[str]) -> nn.Module:\n",
    "    if nonlinearity is None:\n",
    "        return nn.Identity()\n",
    "    if nonlinearity == \"Softmax\":\n",
    "        # For Softmax, we need to specify the channel dimension\n",
    "        return nn.Softmax(dim=1)\n",
    "    if hasattr(nn, nonlinearity):\n",
    "        return getattr(nn, nonlinearity)()\n",
    "    raise ValueError(f\"nonlinearity {nonlinearity} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "@validate_arguments_init\n",
    "@dataclass(eq=False, repr=False)\n",
    "class ConvOp(nn.Sequential):\n",
    "\n",
    "    in_channels: int\n",
    "    out_channels: int\n",
    "    kernel_size: size2t = 3\n",
    "    nonlinearity: Optional[str] = \"LeakyReLU\"\n",
    "    init_distribution: Optional[str] = \"kaiming_normal\"\n",
    "    init_bias: Union[None, float, int] = 0.0\n",
    "\n",
    "    def __post_init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            self.in_channels,\n",
    "            self.out_channels,\n",
    "            kernel_size=self.kernel_size,\n",
    "            padding=self.kernel_size // 2,\n",
    "            padding_mode=\"zeros\",\n",
    "            bias=True,\n",
    "        )\n",
    "\n",
    "        if self.nonlinearity is not None:\n",
    "            self.nonlin = get_nonlinearity(self.nonlinearity)\n",
    "\n",
    "        reset_conv2d_parameters(\n",
    "            self, self.init_distribution, self.init_bias, self.nonlinearity\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@validate_arguments_init\n",
    "@dataclass(eq=False, repr=False)\n",
    "class CrossOp(nn.Module):\n",
    "\n",
    "    in_channels: size2t\n",
    "    out_channels: int\n",
    "    kernel_size: size2t = 3\n",
    "    nonlinearity: Optional[str] = \"LeakyReLU\"\n",
    "    init_distribution: Optional[str] = \"kaiming_normal\"\n",
    "    init_bias: Union[None, float, int] = 0.0\n",
    "\n",
    "    def __post_init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cross_conv = CrossConv2d(\n",
    "            in_channels=as_2tuple(self.in_channels),\n",
    "            out_channels=self.out_channels,\n",
    "            kernel_size=self.kernel_size,\n",
    "            padding=self.kernel_size // 2,\n",
    "        )\n",
    "\n",
    "        if self.nonlinearity is not None:\n",
    "            self.nonlin = get_nonlinearity(self.nonlinearity)\n",
    "\n",
    "        reset_conv2d_parameters(\n",
    "            self, self.init_distribution, self.init_bias, self.nonlinearity\n",
    "        )\n",
    "\n",
    "    def forward(self, target, support):\n",
    "        interaction = self.cross_conv(target, support).squeeze(dim=1)\n",
    "\n",
    "        if self.nonlinearity is not None:\n",
    "            interaction = vmap(self.nonlin, interaction)\n",
    "\n",
    "        new_target = interaction.mean(dim=1, keepdims=True)\n",
    "\n",
    "        return new_target, interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "@validate_arguments_init\n",
    "@dataclass(eq=False, repr=False)\n",
    "class CrossBlock(nn.Module):\n",
    "\n",
    "    in_channels: size2t\n",
    "    cross_features: int\n",
    "    conv_features: Optional[int] = None\n",
    "    cross_kws: Optional[Dict[str, Any]] = None\n",
    "    conv_kws: Optional[Dict[str, Any]] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        conv_features = self.conv_features or self.cross_features\n",
    "        cross_kws = self.cross_kws or {}\n",
    "        conv_kws = self.conv_kws or {}\n",
    "\n",
    "        self.cross = CrossOp(self.in_channels, self.cross_features, **cross_kws)\n",
    "        self.target = Vmap(ConvOp(self.cross_features, conv_features, **conv_kws))\n",
    "        self.support = Vmap(ConvOp(self.cross_features, conv_features, **conv_kws))\n",
    "\n",
    "    def forward(self, target, support):\n",
    "        target, support = self.cross(target, support)\n",
    "        target = self.target(target)\n",
    "        support = self.support(support)\n",
    "        return target, support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "@validate_arguments_init\n",
    "@dataclass(eq=False, repr=False)\n",
    "class UniverSeg(nn.Module):\n",
    "\n",
    "    encoder_blocks: List[size2t]\n",
    "    decoder_blocks: Optional[List[size2t]] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.downsample = nn.MaxPool2d(2, 2)\n",
    "        self.upsample = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "\n",
    "        self.enc_blocks = nn.ModuleList()\n",
    "        self.dec_blocks = nn.ModuleList()\n",
    "\n",
    "        \n",
    "        encoder_blocks = list(map(as_2tuple, self.encoder_blocks))\n",
    "        # print(as_2tuple)\n",
    "        print(encoder_blocks) #[(64, 64), (64, 64), (64, 64), (64, 64)]\n",
    "        decoder_blocks = self.decoder_blocks or encoder_blocks[-2::-1]\n",
    "        decoder_blocks = list(map(as_2tuple, decoder_blocks))\n",
    "        \n",
    "        block_kws = dict(cross_kws=dict(nonlinearity=None))\n",
    "\n",
    "        in_ch = (1, 2)\n",
    "        out_channels = 1\n",
    "        out_activation = None\n",
    "\n",
    "        # Encoder\n",
    "        skip_outputs = []\n",
    "        for (cross_ch, conv_ch) in encoder_blocks:\n",
    "            block = CrossBlock(in_ch, cross_ch, conv_ch, **block_kws)\n",
    "            in_ch = conv_ch\n",
    "            self.enc_blocks.append(block)\n",
    "            skip_outputs.append(in_ch)\n",
    "\n",
    "        # Decoder\n",
    "        skip_chs = skip_outputs[-2::-1]\n",
    "        for (cross_ch, conv_ch), skip_ch in zip(decoder_blocks, skip_chs):\n",
    "            block = CrossBlock(in_ch + skip_ch, cross_ch, conv_ch, **block_kws)\n",
    "            in_ch = conv_ch\n",
    "            self.dec_blocks.append(block)\n",
    "\n",
    "        self.out_conv = ConvOp(\n",
    "            in_ch, out_channels, kernel_size=1, nonlinearity=out_activation,\n",
    "        )\n",
    "\n",
    "    def forward(self, target_image, support_images, support_labels):\n",
    "        # Chuyển đổi target_image thành dạng phù hợp\n",
    "        target = E.rearrange(target_image, \"B 1 H W -> B 1 1 H W\")\n",
    "\n",
    "        # Nối support_images và support_labels để tạo tensor đầu vào\n",
    "        support = torch.cat([support_images, support_labels], dim=2)\n",
    "\n",
    "        # List để lưu trữ đầu ra của mỗi lớp chuyển tiếp\n",
    "        pass_through = []\n",
    "\n",
    "        # Quá trình mã hóa\n",
    "        for i, encoder_block in enumerate(self.enc_blocks):\n",
    "            target, support = encoder_block(target, support)\n",
    "            if i == len(self.encoder_blocks) - 1: #Lớp mã hóa cuối\n",
    "                break\n",
    "            pass_through.append((target, support))\n",
    "            target = vmap(self.downsample, target)\n",
    "            support = vmap(self.downsample, support)\n",
    "\n",
    "        # Quá trình giải mã\n",
    "        for decoder_block in self.dec_blocks:\n",
    "            target_skip, support_skip = pass_through.pop()\n",
    "            target = torch.cat([vmap(self.upsample, target), target_skip], dim=2)\n",
    "            support = torch.cat([vmap(self.upsample, support), support_skip], dim=2)\n",
    "            target, support = decoder_block(target, support)\n",
    "\n",
    "        target = E.rearrange(target, \"B 1 C H W -> B C H W\")\n",
    "        target = self.out_conv(target)\n",
    "\n",
    "        return target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "@validate_arguments\n",
    "def universeg(version: Literal[\"v1\"] = \"v1\", pretrained: bool = False) -> nn.Module:\n",
    "    weights = {\n",
    "        \"v1\": \"https://github.com/JJGO/UniverSeg/releases/download/weights/universeg_v1_nf64_ss64_STA.pt\"\n",
    "    }\n",
    "\n",
    "    if version == \"v1\":\n",
    "        model = UniverSeg(encoder_blocks=[64, 64, 64, 64])\n",
    "\n",
    "    if pretrained:\n",
    "        state_dict = torch.hub.load_state_dict_from_url(weights[version])\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cách hoạt động Encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import einops as E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('UniverSeg')\n",
    "\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cấu trúc 1 layer Encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(64, 64)]\n",
      "ModuleList(\n",
      "  (0): CrossBlock(\n",
      "    (cross): CrossOp(\n",
      "      (cross_conv): CrossConv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (target): Vmap(\n",
      "      (vmapped): ConvOp(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (nonlin): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "    )\n",
      "    (support): Vmap(\n",
      "      (vmapped): ConvOp(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (nonlin): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo mô hình UniverSeg\n",
    "model = UniverSeg(encoder_blocks=[64])\n",
    "\n",
    "\n",
    "print(model.enc_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cấu trúc model với lớp Encoder như trên:\n",
    "- target = E.rearrange(target_image, \"B 1 H W -> B 1 1 H W\")\n",
    "    - Đổi chiều từ (B,1,H,W) thành (B,1,1,H,W)\n",
    "- support = torch.cat([support_images, support_labels], dim=2)\n",
    "    - Nối support_images và support_labels để tạo tensor đầu vào\n",
    "    - (48,1,1,128,128) và (48,1,1,128,128) : Nối theo chiều kênh\n",
    "\n",
    "\n",
    "- List để lưu trữ đầu ra của mỗi lớp chuyển tiếp: pass_through = []\n",
    "\n",
    "- Phần mã hóa:\n",
    "for i, encoder_block in enumerate(self.enc_blocks):\n",
    "    target, support = encoder_block(target, support)\n",
    "    if i == len(self.encoder_blocks) - 1: #Lớp mã hóa cuối\n",
    "        break\n",
    "    pass_through.append((target, support)) #Lưu đầu ra\n",
    "    target = vmap(self.downsample, target) #Áp dụng self.downsample cho target\n",
    "    support = vmap(self.downsample, support)\n",
    "\n",
    "- Ví dụ \n",
    "\n",
    "# Quá trình giải mã\n",
    "for decoder_block in self.dec_blocks:\n",
    "    target_skip, support_skip = pass_through.pop()\n",
    "    target = torch.cat([vmap(self.upsample, target), target_skip], dim=2)\n",
    "    support = torch.cat([vmap(self.upsample, support), support_skip], dim=2)\n",
    "    target, support = decoder_block(target, support)\n",
    "\n",
    "target = E.rearrange(target, \"B 1 C H W -> B C H W\")\n",
    "target = self.out_conv(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList()\n"
     ]
    }
   ],
   "source": [
    "from example_data.wbc import WBCDataset\n",
    "\n",
    "d_support = WBCDataset('JTSC', split='support', label='cytoplasm')\n",
    "d_test = WBCDataset('JTSC', split='test', label='cytoplasm')\n",
    "\n",
    "n_support = 48\n",
    "\n",
    "support_images, support_labels = zip(*itertools.islice(d_support, n_support))\n",
    "support_images = torch.stack(support_images).to(device)\n",
    "support_labels = torch.stack(support_labels).to(device)\n",
    "\n",
    "# Khởi tạo mô hình UniverSeg\n",
    "model = UniverSeg(encoder_blocks=[64, 64, 64, 64])\n",
    "\n",
    "idx = np.random.permutation(len(d_test))[0]\n",
    "image, label = d_test[idx]\n",
    "image, label = image.reshape(1,1,128,128), label.reshape(1,1,128,128)\n",
    "image, label = image.to(device), label.to(device)\n",
    "\n",
    "target = E.rearrange(image, \"B 1 H W -> B 1 1 H W\")\n",
    "support = torch.cat([support_images, support_labels], dim=2)\n",
    "\n",
    "# pass_through = []\n",
    "\n",
    "# for i, encoder_block in enumerate(model.enc_blocks):\n",
    "#     target, support = encoder_block(target, support)\n",
    "#     if i == len(model.encoder_blocks) - 1:\n",
    "#         break\n",
    "#     pass_through.append((target, support))\n",
    "#     target = vmap(model.downsample, target)\n",
    "#     support = vmap(model.downsample, support)\n",
    "\n",
    "# for decoder_block in model.dec_blocks:\n",
    "#     target_skip, support_skip = pass_through.pop()\n",
    "#     target = torch.cat([vmap(model.upsample, target), target_skip], dim=2)\n",
    "#     support = torch.cat([vmap(model.upsample, support), support_skip], dim=2)\n",
    "#     target, support = decoder_block(target, support)\n",
    "\n",
    "model.forward(image, support_images, support_labels)\n",
    "\n",
    "\n",
    "# Chạy quá trình chuyển tiếp\n",
    "# output = model(image, support_images, support_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
